{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a88ebc",
   "metadata": {},
   "source": [
    "## Multiple Layers\n",
    "\n",
    "to add multiple layers, we need an activation function\\\n",
    "tf.nn.relu is one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91bd9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1099997  8.44     ]\n",
      " [ 0.         0.       ]\n",
      " [24.01      38.24     ]]\n"
     ]
    }
   ],
   "source": [
    "# Solution is available in the other \"solution.py\" tab\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "output = None\n",
    "hidden_layer_weights = [\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.4, 0.6, 0.6],\n",
    "    [0.5, 0.9, 0.1],\n",
    "    [0.8, 0.2, 0.8]]\n",
    "out_weights = [\n",
    "    [0.1, 0.6],\n",
    "    [0.2, 0.1],\n",
    "    [0.7, 0.9]]\n",
    "\n",
    "# Weights and biases\n",
    "weights = [\n",
    "    tf.Variable(hidden_layer_weights),\n",
    "    tf.Variable(out_weights)]\n",
    "biases = [\n",
    "    tf.Variable(tf.zeros(3)),\n",
    "    tf.Variable(tf.zeros(2))]\n",
    "\n",
    "# Input\n",
    "features = tf.Variable([[1.0, 2.0, 3.0, 4.0], [-1.0, -2.0, -3.0, -4.0], [11.0, 12.0, 13.0, 14.0]])\n",
    "\n",
    "# TODO: Create Model\n",
    "hidden_layer = tf.add(tf.matmul(features, weights[0]), biases[0])\n",
    "hidden_layer = tf.nn.relu(hidden_layer)\n",
    "\n",
    "logits = tf.add(tf.matmul(hidden_layer, weights[1]), biases[1])\n",
    "\n",
    "# TODO: Print session results\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(logits)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63244acb",
   "metadata": {},
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62dac164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      "[[-0.22406757 -0.8156933  -0.26951525]\n",
      " [-0.70342344 -1.0640975  -0.82342845]]\n",
      "Bias:\n",
      "[ 0.19027528  1.2289932  -1.2760459 ]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "# The file path to save the data\n",
    "save_file = './model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "# Class used to save and/or restore Tensor Variables\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize all the Variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weights:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))\n",
    "\n",
    "    # Save the model\n",
    "    saver.save(sess, save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695f11b8",
   "metadata": {},
   "source": [
    "## Restoring models\n",
    "`saver = tf.train.Saver()` doesn't work if some other extra variables are defined earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403a49e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model.ckpt\n",
      "Weight:\n",
      "[[-0.22406757 -0.8156933  -0.26951525]\n",
      " [-0.70342344 -1.0640975  -0.82342845]]\n",
      "Bias:\n",
      "[ 0.19027528  1.2289932  -1.2760459 ]\n"
     ]
    }
   ],
   "source": [
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]))\n",
    "bias = tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# alternatively\n",
    "# saver = tf.train.import_meta_graph(\"./model.ckpt.meta\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "    # Show the values of weights and bias\n",
    "    print('Weight:')\n",
    "    print(sess.run(weights))\n",
    "    print('Bias:')\n",
    "    print(sess.run(bias))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2985a1b0",
   "metadata": {},
   "source": [
    "## Finetuning\n",
    "we may want to specify a name for each tensor variable\\\n",
    "because our model structure may change as we finetune the architecture\\\n",
    "and loading would yield error if without defined names to track them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "417a9b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save Weights: weights_0:0\n",
      "Save Bias: bias_0:0\n",
      "Load Weights: weights_0:0\n",
      "Load Bias: bias_0:0\n",
      "INFO:tensorflow:Restoring parameters from model.ckpt\n",
      "Loaded Weights and Bias successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "save_file = 'model.ckpt'\n",
    "\n",
    "# Two Tensor Variables: weights and bias\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]), name='weights_0')\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Save Weights: {}'.format(weights.name))\n",
    "print('Save Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, save_file)\n",
    "\n",
    "# Remove the previous weights and bias\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Two Variables: weights and bias\n",
    "bias = tf.Variable(tf.truncated_normal([3]), name='bias_0')\n",
    "weights = tf.Variable(tf.truncated_normal([2, 3]) ,name='weights_0')\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Print the name of Weights and Bias\n",
    "print('Load Weights: {}'.format(weights.name))\n",
    "print('Load Bias: {}'.format(bias.name))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Load the weights and bias - No Error\n",
    "    saver.restore(sess, save_file)\n",
    "\n",
    "print('Loaded Weights and Bias successfully.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a739138",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "In order to compensate for dropped units, `tf.nn.dropout()` multiplies all units that are kept (i.e. not dropped) by `1/keep_prob`.\n",
    "\n",
    "### usage\n",
    "```python\n",
    "hidden_layer = tf.nn.dropout(hidden_layer, keep_prob)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef725dd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
